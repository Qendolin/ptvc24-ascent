#version 450

// Copy of https://github.com/bevyengine/bevy/blob/2aed777435d26c357ed71cdb8c7b858de35e582e/crates/bevy_pbr/src/ssao/gtao.wgsl

// Ground Truth-based Ambient Occlusion (GTAO)
// Paper: https://www.activision.com/cdn/research/Practical_Real_Time_Strategies_for_Accurate_Indirect_Occlusion_NEW%20VERSION_COLOR.pdf
// Presentation: https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf

// Source code heavily based on XeGTAO v1.30 from Intel
// https://github.com/GameTechDev/XeGTAO/blob/0d177ce06bfa642f64d8af4de1197ad1bcb862d4/Source/Rendering/Shaders/XeGTAO.hlsli

// Further References:
// https://github.com/AmplifyCreations/AmplifyOcclusion/blob/809c2782bd54abb743d55c89488fed8a72fe8905/Assets/AmplifyOcclusion/Resources/GTAO.cginc
// https://github.com/bferan/lucent/blob/b19163df12739ffc513110d927e92f98c0b54321/src/shaders/GTAO.shader
// https://github.com/MaxwellGengYF/Unity-Ground-Truth-Ambient-Occlusion/blob/9cc30e0f31eb950a994c71866d79b2798d1c508e/Shaders/GTAO_Common.cginc#L146
// https://github.com/bladesero/GTAO_URP/blob/a8adefa0750741b56e77d40175d782c3a5009407/Resources/GTAO.hlsl

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

const float PI = 3.14159265359;
const float HALF_PI = PI / 2.0;

layout(binding = 0) uniform sampler2D in_depth_mips;
layout(binding = 1) uniform sampler2D in_view_normals;
layout(binding = 0, r16f) uniform writeonly restrict image2D ambient_occlusion;
layout(binding = 1, r32ui) uniform writeonly restrict uimage2D depth_differences;
layout(binding = 2, r16ui) uniform readonly restrict uimage2D hilbert_index_lut;

uniform uint u_frame;
uniform mat4 u_inverse_projection_mat;
uniform mat4 u_projection_mat;
uniform float u_power;
uniform float u_factor;
uniform float u_radius;

// Approximates single-bounce ambient occlusion to multi-bounce ambient occlusion
// https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf#page=78
vec3 gtao_multibounce(float visibility, vec3 base_color) {
    vec3 a = 2.0404 * base_color - 0.3324;
    vec3 b = -4.7951 * base_color + 0.6417;
    vec3 c = 2.7552 * base_color + 0.6903;
    vec3 x = vec3(visibility);
    return max(x, ((x * a + b) * x + c) * x);
}

float fast_sqrt(float x) {
    return intBitsToFloat(0x1fbd1df5 + (floatBitsToInt(x) >> 1));
}

float fast_acos(float in_x) {
    float x = abs(in_x);
    float res = -0.156583 * x + 1.57079632679;
    res *= fast_sqrt(1.0 - x);
    return mix(PI - res, res, in_x >= 0.0);
}

#define TEMPORAL_JITTER

vec2 load_noise(ivec2 tex_coords) {
    uint index = imageLoad(hilbert_index_lut, tex_coords % 64).r;

#ifdef TEMPORAL_JITTER
    index += 288u * (u_frame % 64u);
#endif

	// R2 sequence - http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences
    return fract(0.5 + float(index) * vec2(0.75487766624669276005, 0.5698402909980532659114));
}

// Calculate differences in depth between neighbor pixels (later used by the spatial denoiser pass to preserve object edges)
float calculate_neighboring_depth_differences(ivec2 tex_coords, vec2 texel_size) {
	// Sample the pixel's depth and 4 depths around it
    vec2 uv = vec2(tex_coords) * texel_size;
    vec4 depths_upper_left = textureGather(in_depth_mips, uv);
    vec4 depths_bottom_right = textureGatherOffset(in_depth_mips, uv, ivec2(1, 1));
    float depth_center = depths_upper_left.y;
    float depth_left = depths_upper_left.x;
    float depth_top = depths_upper_left.z;
    float depth_bottom = depths_bottom_right.x;
    float depth_right = depths_bottom_right.z;

	// Calculate the depth differences (large differences represent object edges)
    vec4 edge_info = vec4(depth_left, depth_right, depth_top, depth_bottom) - depth_center;
    float slope_left_right = (edge_info.y - edge_info.x) * 0.5;
    float slope_top_bottom = (edge_info.w - edge_info.z) * 0.5;
    vec4 edge_info_slope_adjusted = edge_info + vec4(slope_left_right, -slope_left_right, slope_top_bottom, -slope_top_bottom);
    edge_info = min(abs(edge_info), abs(edge_info_slope_adjusted));
    float bias = 0.25; // Using the bias and then saturating nudges the values a bit
    float scale = depth_center * 0.011; // Weight the edges by their distance from the camera
    edge_info = clamp((1.0 + bias) - edge_info / scale, 0.0, 1.0); // Apply the bias and scale, and invert edge_info so that small values become large, and vice versa

	// Pack the edge info into the texture
    uvec4 edge_info_packed = uvec4(packUnorm4x8(edge_info), 0u, 0u, 0u);
    imageStore(depth_differences, tex_coords, edge_info_packed);

    return depth_center;
}

vec2 sign_not_zero(vec2 v) {
    return fma(step(vec2(0.0), v), vec2(2.0), vec2(-1.0));
}

// Unpacking from octahedron normals
// https://discourse.panda3d.org/t/glsl-octahedral-normal-packing/15233
vec3 unpack_normal(vec2 n) {
  vec3 v = vec3(n.xy, 1.0 - abs(n.x) - abs(n.y));
  if (v.z < 0) v.xy = (1.0 - abs(v.yx)) * sign_not_zero(v.xy);
  return normalize(v);
}

vec3 load_normal_view_space(vec2 uv) {
    vec2 packed_normal = texture(in_view_normals, uv).xy;
	return unpack_normal(packed_normal);
}

vec3 reconstruct_view_space_position(float depth, vec2 uv) {
    vec2 clip_xy = uv * 2.0 - 1.0;
    vec4 t = u_inverse_projection_mat * vec4(clip_xy, depth, 1.0);
    t.xyz *= vec3(1, -1, -1);
    return t.xyz / t.w;
}

vec3 load_and_reconstruct_view_space_position(vec2 uv, float sample_mip_level) {
    float depth = textureLod(in_depth_mips, uv, sample_mip_level).r;
    return reconstruct_view_space_position(depth, uv);
}

#define SLICE_COUNT 3
#define SAMPLES_PER_SLICE_SIDE 7
#define Z_CUTOFF 0.00001

void main() {
    float slice_count = float(SLICE_COUNT);
    float samples_per_slice_side = float(SAMPLES_PER_SLICE_SIDE);
    float effect_radius = u_radius * 1.457; // TODO: Why 1.475?
    float min_sample_distance = 1.3; // this is the min distance to start sampling from to avoid sampling from the center pixel (no useful data obtained from sampling center pixel)
    float falloff_range = 0.615 * effect_radius;
    float falloff_from = effect_radius * (1.0 - 0.615);
    float falloff_mul = -1.0 / falloff_range;
    float falloff_add = falloff_from / falloff_range + 1.0;

    ivec2 tex_coords = ivec2(gl_GlobalInvocationID.xy);
	vec2 texture_size = vec2(imageSize(ambient_occlusion).xy);
	vec2 texel_size = 1.0 / texture_size;
    vec2 uv = (vec2(tex_coords) + 0.5) * texel_size;

    float pixel_depth = calculate_neighboring_depth_differences(tex_coords, texel_size);
    if(pixel_depth <= Z_CUTOFF) { // far plane cutoff
        // Avoid depth precision issues
        imageStore(ambient_occlusion, tex_coords, vec4(1.0, 0.0, 0.0, 0.0));
        return;
    }

    vec3 pixel_position = reconstruct_view_space_position(pixel_depth, uv);
    vec3 pixel_normal = load_normal_view_space(uv);
    pixel_normal *= vec3(1, -1, -1);
    vec3 view_vec = normalize(-pixel_position);

    vec2 noise = load_noise(tex_coords);
    float screen_space_radius = 0.5 * effect_radius * u_projection_mat[1][1] / pixel_position.z;
    float aspect = u_projection_mat[0][0] / u_projection_mat[1][1];
    
    
    // Need division because of multipication later
    min_sample_distance /= (screen_space_radius * texture_size.y); 

    float visibility = 0.0;
    for (float slice_t = 0.0; slice_t < slice_count; slice_t += 1.0) {
        float slice = slice_t + noise.x;
        float phi = slice * PI / slice_count;
        vec2 omega = vec2(cos(phi), sin(phi));


        vec3 direction = vec3(omega, 0.0);
        // Project the direction onto the view plane.
        vec3 orthographic_direction = direction - (dot(direction, view_vec) * view_vec);

        // S_n, the normal of the "slice" plane (62)
        vec3 slice_N = cross(direction, view_vec);
        // Project the direction onto the slice plane.
        vec3 projected_normal = pixel_normal - (dot(pixel_normal, slice_N) * slice_N);
        float projected_normal_length = length(projected_normal);

        float sign_norm = sign(dot(orthographic_direction, projected_normal));
        float cos_norm = clamp(dot(projected_normal, view_vec) / projected_normal_length, 0.0, 1.0);
        // angle of the projected normal, called "n" in the paper and slides
        float normal_angle = sign_norm * fast_acos(cos_norm);

        // this is a lower weight target; not using -1 as in the original paper because it is under horizon, so a 'weight' has different meaning based on the normal
        float min_cos_horizon_1 = cos(normal_angle + HALF_PI);
        float min_cos_horizon_2 = cos(normal_angle - HALF_PI);
        float cos_horizon_1 = min_cos_horizon_1;
        float cos_horizon_2 = min_cos_horizon_2;

        // Find max horizon angles in each direction
        for (float sample_t = 0.0; sample_t < samples_per_slice_side; sample_t += 1.0) {
            float sample_noise = (slice_t + sample_t * samples_per_slice_side) * 0.6180339887498948482;
            sample_noise = fract(noise.y + sample_noise);

            float s = (sample_t + sample_noise) / samples_per_slice_side;
            s *= s; // https://github.com/GameTechDev/XeGTAO#sample-distribution
            s += min_sample_distance;
            vec2 sample_offset_uv = s * omega * screen_space_radius * vec2(aspect, -1);
			// texture_size gets us from [0, 1] to [0, texture_size], which is needed for this to get the correct mip levels
            float sample_offset_length = length(sample_offset_uv * texture_size);

            float sample_mip_level = clamp(log2(sample_offset_length) - 3.3, 0.0, 5.0);  // https://github.com/GameTechDev/XeGTAO#memory-bandwidth-bottleneck

            vec3 sample_position_1 = load_and_reconstruct_view_space_position(uv + sample_offset_uv, sample_mip_level);
            vec3 sample_position_2 = load_and_reconstruct_view_space_position(uv - sample_offset_uv, sample_mip_level);

            vec3 sample_difference_1 = sample_position_1 - pixel_position;
            vec3 sample_difference_2 = sample_position_2 - pixel_position;
            float sample_distance_1 = length(sample_difference_1);
            float sample_distance_2 = length(sample_difference_2);
            float sample_cos_horizon_1 = dot(sample_difference_1 / sample_distance_1, view_vec);
            float sample_cos_horizon_2 = dot(sample_difference_2 / sample_distance_2, view_vec);

            // any sample out of radius should be discarded - also use fallof range for smooth transitions; this is a modified idea from "4.3 Implementation details, Bounding the sampling area"
            float weight_1 = clamp(sample_distance_1 * falloff_mul + falloff_add, 0.0, 1.0);
            float weight_2 = clamp(sample_distance_2 * falloff_mul + falloff_add, 0.0, 1.0);
            sample_cos_horizon_1 = mix(min_cos_horizon_1, sample_cos_horizon_1, weight_1);
            sample_cos_horizon_2 = mix(min_cos_horizon_2, sample_cos_horizon_2, weight_2);

            cos_horizon_1 = max(cos_horizon_1, sample_cos_horizon_1);
            cos_horizon_2 = max(cos_horizon_2, sample_cos_horizon_2);
        }

        float horizon_1 = fast_acos(cos_horizon_1);
        float horizon_2 = -fast_acos(cos_horizon_2);

        float v1 = (cos_norm + 2.0 * horizon_1 * sin(normal_angle) - cos(2.0 * horizon_1 - normal_angle)) / 4.0;
        float v2 = (cos_norm + 2.0 * horizon_2 * sin(normal_angle) - cos(2.0 * horizon_2 - normal_angle)) / 4.0;
        
        visibility += projected_normal_length * (v1 + v2);
    }
    visibility /= slice_count;
    visibility = min(visibility, 1.0);

    // Fade out at great distance to avoid artifacts
    // TODO: test if this works as intendet
    visibility = mix(1.0, visibility, clamp(pixel_depth / Z_CUTOFF - 1.0, 0.0, 1.0));

    // pow allows for adjustment of the look
    visibility = pow(visibility, u_power);
    visibility = 1.0 - (1.0 - visibility) * u_factor;
    // disallow total occlusion
    visibility = max(visibility, 0.03);

    imageStore(ambient_occlusion, tex_coords, vec4(visibility, 0.0, 0.0, 0.0));
}
